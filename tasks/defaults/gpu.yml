# resources
cuda: true
fp16: false

# env
vectorized: true
multi_proc: true
numenv: 4
horizon: 1000

# logging
wandb_project: "damnlemons"
record: false
render: false

# training
num_timesteps: 10000000
training_steps_per_iter: 1
eval_steps_per_iter: 10
eval_every: 100

# model
layer_norm: true

# optimization
actor_lr: 2.5e-4
critic_lr: 2.5e-4
clip_norm: 5.
wd_scale: 0.

# algorithm
segment_len: 1
batch_size: 64
gamma: 0.99
rbx_capacity: 250000
polyak: 0.005
targ_up_freq: 100
n_step_returns: false
lookahead: 5
ret_norm: false
prefer_td3_over_sac: true

# TD3
normal_noise_std: 0.1
clipped_double: true
bcq_style_targ_mix: true
targ_actor_smoothing: true
td3_std: 0.2
td3_c: 0.5
actor_update_delay: 2

# SAC
state_dependent_std: true
alpha_init: 0.1
learnable_alpha: true
log_alpha_lr: 1e-4
crit_targ_update_freq: 2

# distributional RL
use_c51: false
use_qr: false
c51_num_atoms: 51
c51_vmin: -100.
c51_vmax: 100.
num_tau: 200

# AIL
g_steps: 1
d_steps: 1
d_lr: 5.0e-4
state_only: false
minimax_only: true
d_label_smooth: 0.25
ent_reg_scale: 0.0001
spectral_norm: true
grad_pen: true
grad_pen_targ: 1.
grad_pen_scale: 10.
one_sided_pen: true
historical_patching: true
wrap_absorb: true
d_batch_norm: false
d_layer_norm: true

# pathways to recovery
rl_mode: false
enable_sr: false
separate: true
tsx_capacity: 10000
em_mxlen: 1000
amortized_advantage: false
lstm_mode: false
sr_alpha: 0.2
sr_beta: 1.
